{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "df = pd.read_csv(f\"{data_path}/twitter_training.csv\",names=[\"index_category\", \"game_category\",\"sentiment_category\",\"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_category</th>\n",
       "      <th>game_category</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_category game_category sentiment_category  \\\n",
       "0            2401   Borderlands           Positive   \n",
       "1            2401   Borderlands           Positive   \n",
       "2            2401   Borderlands           Positive   \n",
       "3            2401   Borderlands           Positive   \n",
       "4            2401   Borderlands           Positive   \n",
       "\n",
       "                                               Tweet  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='index_category',axis=1)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentiment_category'] != 'Irrelevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_emoji():\n",
    "  regex_pattern = re.compile(pattern = \"[\"    #Pattern pour enlever les emojis\n",
    "          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "          u\"\\U00002702-\\U000027B0\"\n",
    "          u\"\\U00002702-\\U000027B0\"\n",
    "          u\"\\U000024C2-\\U0001F251\"\n",
    "          u\"\\U0001f926-\\U0001f937\"\n",
    "          u\"\\U00010000-\\U0010ffff\"\n",
    "          u\"\\u2640-\\u2642\" \n",
    "          u\"\\u2600-\\u2B55\"\n",
    "          u\"\\u200d\"\n",
    "          u\"\\u23cf\"\n",
    "          u\"\\u23e9\"\n",
    "          u\"\\u231a\"\n",
    "          u\"\\ufe0f\"  # dingbats\n",
    "          u\"\\u3030\"\n",
    "                            \"]+\", flags = re.UNICODE)\n",
    "  return regex_pattern\n",
    "\n",
    "def lematize(text):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    On retire tout d'abord nettoyer les tweets qui ne pourront pas nous servir\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'{link}', '',text) #Remove links \n",
    "    text = re.sub(r\"\\[video\\]\", '',text) #Remove videos\n",
    "    text = re.sub(r'&[a-z]+;', '',text) #Remove HTML references\n",
    "\n",
    "    text = re.sub(r'@\\w+', '', text) #Remove mention\n",
    "    text = re.sub(r'#\\w+', '', text) #Remove hashtag\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text) #Remove numbers \n",
    "    text = re.sub(r'http\\S+', '',text) #Remove HTML\n",
    "    text = re.sub(r'www\\S+', '',text) #Remove HTML\n",
    "    text = re.sub(r'[^\\w\\s]+',' ',text) #Remove ponctuation et apostrophes\n",
    "    text = re.sub(r'\\s+',' ', text) #Remove new line characters\n",
    "    text = re.sub(r'[^\\w\\s]+',' ',text) #Remove ponctuation et apostrophes\n",
    "    text = re.sub(remove_emoji(),'',text)  #Remove les emojis\n",
    "    text = lematize(text) #Lemmatization\n",
    "\n",
    "    \"\"\"\n",
    "    Puis on souhaitera de transformer les mots courants vers des mots plus expressives en anglais\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"won\\'t\", \"would not\", text)\n",
    "    text = re.sub(r\"im\", \"i am\", text)\n",
    "    text = re.sub(r\"Im\", \"I am\", text)\n",
    "    text  = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text  = re.sub(r\"don\\'t\", \"do not\", text)\n",
    "    text  = re.sub(r\"shouldn\\'t\", \"should not\", text)\n",
    "    text  = re.sub(r\"needn\\'t\", \"need not\", text)\n",
    "    text  = re.sub(r\"hasn\\'t\", \"has not\", text)\n",
    "    text  = re.sub(r\"haven\\'t\", \"have not\", text)\n",
    "    text  = re.sub(r\"weren\\'t\", \"were not\", text)\n",
    "    text  = re.sub(r\"mightn\\'t\", \"might not\", text )\n",
    "    text  = re.sub(r\"didn\\'t\", \"did not\", text )\n",
    "    text  = re.sub(r\"n\\'t\", \" not\", text )\n",
    "    text  = re.sub(r\"\\'re\", \" are\", text )\n",
    "    text  = re.sub(r\"\\'s\", \" is\", text )\n",
    "    text  = re.sub(r\"\\'d\", \" would\", text )\n",
    "    text  = re.sub(r\"\\'ll\", \" will\", text )\n",
    "    text  = re.sub(r\"\\'t\", \" not\", text )\n",
    "    text  = re.sub(r\"\\'ve\", \" have\", text )\n",
    "    text  = re.sub(r\"\\'m\", \" am\", text )\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords from the tokenized text\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in english_stopwords]\n",
    "\n",
    "    # Join the filtered tokens back into a single string\n",
    "    filtered_text = \" \".join(filtered_tokens)\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].fillna(\"\")\n",
    "df['tweet_clean'] = df['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_category</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>getting borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>coming border kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>getting borderland kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>coming borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>getting borderland murder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  game_category sentiment_category  \\\n",
       "0   Borderlands           Positive   \n",
       "1   Borderlands           Positive   \n",
       "2   Borderlands           Positive   \n",
       "3   Borderlands           Positive   \n",
       "4   Borderlands           Positive   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                 tweet_clean  \n",
       "0  getting borderland murder  \n",
       "1         coming border kill  \n",
       "2    getting borderland kill  \n",
       "3   coming borderland murder  \n",
       "4  getting borderland murder  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering TF-IDF et s√©paration de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet_clean']\n",
    "y = df['sentiment_category']\n",
    "\n",
    "words_to_remove = ['dead','com','wa','pic','get','unk','ti','red','redemption','borderland','ame','one','gta','creed','assassin','go',\n",
    "                   'look','tv','ha','call','duty','twitter','fifa','pubg','player','ban','battlefield','see','league','legend','twitch','rhandlerr','still']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features = 1000,\n",
    "    stop_words=words_to_remove,\n",
    "    max_df=0.8, \n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train_vec = vectorizer.fit_transform(X_train) #Entrainement 80%\n",
    "X_val_vec = vectorizer.transform(X_val) #Validation 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des valeurs Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des cat√©gories\n",
    "sentiments = LabelEncoder()\n",
    "df['sentiment_category_encoded'] = sentiments.fit_transform(df['sentiment_category'])\n",
    "y = df['sentiment_category_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application MLFlow\n",
    "\n",
    "Voici la commande qui permet de lancer MLflow sur votre console <br>\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'exp√©rience 'Tweets_model' a √©t√© cr√©√©e avec l'ID 129569839661631736.\n"
     ]
    }
   ],
   "source": [
    "# Description de l'exp√©rience\n",
    "experiment_description = (\n",
    "    \"This is the sentiments-analysis-tweets project. \"\n",
    "    \"This experiment contains the produce models for Tweets\"\n",
    ")\n",
    "\n",
    "# Tags de l'exp√©rience\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"sentiment-analysis\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Nom de l'exp√©rience\n",
    "experiment_name = \"Tweets_model\"\n",
    "\n",
    "# V√©rifier si l'exp√©rience existe d√©j√†\n",
    "existing_experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if existing_experiment:\n",
    "    print(f\"L'exp√©rience '{experiment_name}' existe d√©j√† avec l'ID {existing_experiment.experiment_id}.\")\n",
    "    experiment_id = existing_experiment.experiment_id\n",
    "else:\n",
    "    # Cr√©er l'exp√©rience si elle n'existe pas\n",
    "    experiment_id = client.create_experiment(name=experiment_name, tags=experiment_tags)\n",
    "    print(f\"L'exp√©rience '{experiment_name}' a √©t√© cr√©√©e avec l'ID {experiment_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_experiment_id': '129569839661631736', '_name': 'Tweets_model', '_artifact_location': 'mlflow-artifacts:/129569839661631736', '_lifecycle_stage': 'active', '_tags': {'mlflow.note.content': 'This is the sentiments-analysis-tweets project. This experiment contains the produce models for Tweets', 'project_name': 'sentiment-analysis', 'project_quarter': 'Q3-2025', 'store_dept': 'produce', 'team': 'stores-ml'}, '_creation_time': 1742334520442, '_last_update_time': 1742334520442}\n"
     ]
    }
   ],
   "source": [
    "tweets_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'sentiment-analysis'\"\n",
    ")\n",
    "\n",
    "print(vars(tweets_experiment[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premi√®re connexion sur MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_experiment = mlflow.set_experiment(\"Tweets_model\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name_RF = \"test_2_random_forest\"\n",
    "run_name_LR = \"test_2_logistic_regression\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"artefact_model_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_randomforest = {\n",
    "    'n_estimators': 200,   # Distribution pour le nombre d'arbres\n",
    "    'max_depth': None,     # Max profondeur de l'arbre\n",
    "    'min_samples_split': 4,  # Nombre minimal d'√©chantillons\n",
    "    'min_samples_leaf': 3    # Nombre de feuilles\n",
    "}\n",
    "\n",
    "params_logisticregression = {\n",
    "    'penalty': 'l2',            # R√©gularisation L1, L2 par d√©faut 'l2')\n",
    "    'C': 1.0,                   # Inverse de la force de r√©gularisation (plus grand C = moins de r√©gularisation)\n",
    "    'solver': 'lbfgs',          # Algorithme d'optimisation ('lbfgs' recommand√© pour multi-classes)\n",
    "    'max_iter': 1200,           # Nombre max d'it√©rations pour la convergence\n",
    "    'multi_class': 'multinomial',  # Mode multinomial pour classification multi-classes\n",
    "    'random_state': 44         # Fixer le g√©n√©rateur al√©atoire pour reproductibilit√©\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 56.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run test_2_random_forest at: http://127.0.0.1:8080/#/experiments/129569839661631736/runs/2f94905055f24374bdafceaaf23a97a5\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/129569839661631736\n"
     ]
    }
   ],
   "source": [
    "# Mod√®le Random forest\n",
    "model_RFC = RandomForestClassifier(**params_randomforest)\n",
    "model_RFC.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model_RFC.predict(X_val_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred) \n",
    "precision = precision_score(y_val, y_pred,average=\"macro\") \n",
    "recall = recall_score(y_val, y_pred,average=\"macro\") \n",
    "\n",
    "metrics_RFC = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_RF) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params_randomforest)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics_RFC)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_RFC, input_example=X_val_vec, artifact_path=artifact_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\Desktop\\PROJETS\\MLOps\\Deploiement_project_MLops\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 81.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run test_2_logistic_regression at: http://127.0.0.1:8080/#/experiments/129569839661631736/runs/0502eebd41654c07b255488bacde3a55\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/129569839661631736\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression(**params_logisticregression)\n",
    "model_LR.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model_LR.predict(X_val_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred) \n",
    "precision = precision_score(y_val, y_pred,average=\"macro\") \n",
    "recall = recall_score(y_val, y_pred,average=\"macro\") \n",
    "\n",
    "\n",
    "metrics_RFC = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_LR) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params_logisticregression)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics_RFC)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_LR, input_example=X_val_vec, artifact_path=artifact_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder le meilleur mod√®le et le vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = \"models\"\n",
    "\n",
    "with open(f\"{path_models}/RandomClassifierForest.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model_LR, file)\n",
    "\n",
    "with open(f\"{path_models}/tfidf_vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
